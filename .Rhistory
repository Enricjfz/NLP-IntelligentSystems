plot(cars)
urlQuijoteGutenber <- "https://www.gutenberg.org/files/2000/2000-0.txt"
lines <- readLines(urlQuijoteGutenber,
encoding = "UTF-8") #It takes a few seconds
grep(pattern = "***", lines, fixed = TRUE) #Warning! Without fixed the regex is "\\*\\*\\*"
linesQ <- lines[25:37703]
length(linesQ) #37,679
grep(pattern = "En un lugar de",
linesQ,
fixed = TRUE) #Lines 1045 and 13513. The good one is the first one
linesQ <- linesQ[-c(1:1044)] #Remove the prologue
length(linesQ) #36,635
library(utf8)
#Check character normalization. Specifically, the normalized composed form (NFC)
linesQ_NFC <- utf8_normalize(linesQ)
sum(linesQ_NFC != linesQ) #0 means all right. The text is in NFC.
linesQ
stringQ <- paste(linesQ, collapse = "\n") #One big string
paragraphs <- unlist(strsplit(stringQ, "\\n\\n\\n"))#Warn! (1)strsplit returns a list,
# (2)escape \n and
# (3)by default, fixed=FALSE
#Using fixed=TRUE this should be
# "\n\n\n", fixed = TRUE
parEmpty <- which(paragraphs == "") #No empty paragraphs
#paragraphs <- paragraphs[-parEmpty]
length(paragraphs) # 128
substring(paragraphs[1], 1, 200)
clear
#Testing the regex
gsub("[\n]{1,}", " ", c(par1="with one \nbut also\n",
par2="with a seq of \n\nlike this"
)
)
paragraphswoNL <- gsub("[\n]{1,}", " ", paragraphs) #wo = without
substring(paragraphswoNL[1], 1, 200)
paragraphs <- gsub("[ ]{2,}", " ", paragraphswoNL) #We reassign the varible paragraphs
substring(paragraphs[1], 1, 200)
paragraphs[1]
paragraphs[1]
library(quanteda)
library(syuzhet)
library("tokenizers.bpe")
s_v <- get_sentences(paragraphs[1])
class(s_v)
str(s_v)
head(s_v)
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
head(syuzhet_vector)
bing_vector <- get_sentiment(s_v, method = "bing")
head(bing_vector)
afinn_vector <- get_sentiment(s_v, method = "afinn")
head(afinn_vector)
nrc_vector <- get_sentiment(s_v, method = "nrc", lang = "english")
nrc_vector <- get_sentiment(s_v, method = "nrc", lang = "spanish")
head(nrc_vector)
rbind(
sign(head(syuzhet_vector)),
sign(head(bing_vector)),
sign(head(afinn_vector)),
sign(head(nrc_vector))
)
sum(syuzhet_vector)
mean(syuzhet_vector)
summary(syuzhet_vector)
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
s_v <- get_sentences(paragraphs[2])
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
paragraphs[2]
str(s_v)
head(s_v)
library(quanteda)
library(syuzhet)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
plot(
syuzhet_vector,
type="h",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
plot(
syuzhet_vector,
type="h",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
percent_vals <- get_percentage_values(syuzhet_vector, bins = 10)
plot(
percent_vals,
type="l",
main="Joyce's Portrait Using Percentage-Based Means",
xlab = "Narrative Time",
ylab= "Emotional Valence",
col="red"
)
percent_vals <- get_percentage_values(syuzhet_vector, bins = 20)
plot(
percent_vals,
type="l",
main="Joyce's Portrait Using Percentage-Based Means",
xlab = "Narrative Time",
ylab= "Emotional Valence",
col="red"
)
dct_values <- get_dct_transform(
syuzhet_vector,
low_pass_size = 5,
x_reverse_len = 100,
scale_vals = F,
scale_range = T
)
plot(
dct_values,
type ="l",
main ="Joyce's Portrait using Transformed Values",
xlab = "Narrative Time",
ylab = "Emotional Valence",
col = "red"
)
simple_plot(syuzhet_vector)
simple_plot(syuzhet_vector)
nrc_data <- get_nrc_sentiment(s_v)
angry_items <- which(nrc_data$anger > 0)
s_v[angry_items]
library(quanteda)
library(syuzhet)
texto <- "No me gusta nada la asignatura de Sistemas inteligentes, me parece
muy aburrida"
sent = get_sentences(texto)
vector <- get_sentiment(sent, method="syuzhet")
source("C:/Users/Enrique/Desktop/Enrique/Universidad/master/intelligent systems/NLPDeliverable/prueba.R")
simple_plot(vector)
summary(vector)
library(quanteda)
library(syuzhet)
paragraphs[1]
paragraphs[3]
s_v <- get_sentences(paragraphs[3])
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
s_v <- get_sentences(paragraphs[4])
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
s_v <- get_sentences(paragraphs[3])
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
s_v <- get_sentences(paragraphs[5])
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
paragraphs[3]
len(paragraphs[3])
rm(sent)
rm(texto)
rm(vector)
s_v <- get_sentences(paragraphs[3])
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
simple_plot(syuzhet_vector)
library(quanteda)
library(syuzhet)
simple_plot(syuzhet_vector)
nrc_data <- get_nrc_sentiment(s_v)
angry_items <- which(nrc_data$anger > 0)
s_v[angry_items]
library(quanteda.sentiment)
cs = corpus(paragraphs[3])
paragraph_analize = paragraphs[3][-c(1,2,3)]
rm(paragraph_analize)
summary(cs)
metadoc(cs, "language") <- "spanish"
library("quanteda.sentiment")
tokens_lookup(tokens(paragraphs[3]), dictionary = data_dictionary_LSD2015, exclusive = FALSE)
cs = corpus(paragraphs)
summary(cs)
rm(stringQ)
rm(linesQ)
s_v <- get_sentences(paragraphs)
syuzhet_vector <- get_sentiment(s_v, method="syuzhet")
summary(syuzhet_vector)
s_v_sentiment <- get_sentiment(s_v)
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
simple_plot(syuzhet_vector)
polarity(data_dictionary_LSD2015) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
library(quanteda)
polarity(data_dictionary_LSD2015) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
library("quanteda.sentiment", warn.conflicts = FALSE, verbose = FALSE)
install.packages("remotes")
remotes::install_github("quanteda/quanteda.sentiment")
library("quanteda.sentiment")
library("quanteda.sentiment", warn.conflicts = FALSE, verbose = FALSE)
polarity(data_dictionary_LSD2015) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
sent_pres <- cs %>%
textstat_polarity(data_dictionary_LSD2015)
sent_pres
library("ggplot2")
ggplot(sent_pres) +
geom_point(aes(x = sentiment, y = reorder(doc_id, sentiment))) +
ylab("")
toks <- tokens(paragraphs)
valence(data_dictionary_LSD2015) <- list(positive = 1, negative = -1)
textstat_valence(toks, data_dictionary_LSD2015)
dfm_lookup(dfm(toks), data_dictionary_LSD2015)
ggplot(sent_pres) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment)) +
ylab("")  #no es muy legible
plot(
s_v_sentiment,
type="l",
main="Example Plot Trajectory",
xlab = "Narrative Time",
ylab= "Emotional Valence"
)
simple_plot(syuzhet_vector)
tail(cs) %>%
textstat_polarity(dictionary = data_dictionary_geninqposneg)
tail(cs) %>%
textstat_polarity(dictionary = data_dictionary_LSD2015)
tail(cs) %>%
textstat_valence(dictionary = data_dictionary_ANEW["pleasure"])
head
tail(cs) %>%
textstat_valence(dictionary = data_dictionary_ANEW["arousal"])
tail(cs) %>%
textstat_valence(dictionary = data_dictionary_ANEW["arousal"])
sent_pol <- tail(cs, 25) %>%
textstat_polarity(dictionary = data_dictionary_LSD2015)
data("data_dictionary_LSD2015", package = "quanteda.sentiment")
sent_pol <- tail(cs, 25) %>%
textstat_polarity(dictionary = data_dictionary_LSD2015)
sent_pol <- dplyr::mutate(sent_pol, polarity = sentiment)
sent_val <- tail(cs, 25) %>%
textstat_valence(dictionary = data_dictionary_AFINN)
ggplot(data.frame(sent_pol, valence = sent_val$sentiment),
aes(x = polarity, y = valence)) +
geom_point()
library(quanteda)
library(syuzhet)
library("tokenizers.bpe")
library(quanteda)
# create corpus
corpus = Corpus(VectorSource(all))
library(quanteda)
library(syuzhet)
simple_plot(syuzhet_vector)
#valence barplot
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in Sample text", xlab="Percentage"
)
barplot(
sort(colSums(prop.table(nrc_data[, 9:10]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in Sample text", xlab="Percentage"
)
#valence barplot
par(mfrow = c(1,2))
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in Sample text", xlab="Percentage"
)
barplot(
sort(colSums(prop.table(nrc_data[, 9:10]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in Sample text", xlab="Percentage"
)
#valence barplot
par(mfrow = c(1,2))
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col = c(1,2),
main = "Emotions in Sample text", xlab="Percentage"
)
barplot(
sort(colSums(prop.table(nrc_data[, 9:10]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col = c(1,2),
main = "Emotions in Sample text", xlab="Percentage"
)
#valence barplot
par(mfrow = c(1,2))
barplot(
sort(colSums(prop.table(nrc_data[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col = c(1,2,3,4,5,6,7,8),
main = "Emotions in Sample text", xlab="Percentage"
)
barplot(
sort(colSums(prop.table(nrc_data[, 9:10]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
col = c(1,2),
main = "Emotions in Sample text", xlab="Percentage"
)
angry_items <- which(nrc_data$anger > 0)
s_v[angry_items]
trust_items <- which(nrc_data$trust > 0)
s_v[trust_items]
polarity(data_dictionary_NRC) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
data("data_dictionary_NRC",package = "quanteda.sentiment")
polarity(data_dictionary_NRC) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
library("quanteda.sentiment")
polarity(data_dictionary_NRC) <-
list(pos = c("positive", "neg_negative"), neg = c("negative", "neg_positive"))
polarity(data_dictionary_NRC) <-
list(pos = c("positive"), neg = c("negative"))
sent_pres <- cs %>%
textstat_polarity(data_dictionary_NRC)
sent_pres
ggplot(sent_pres) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment)) +
ylab("")  #no es muy legible
library("ggplot2")
ggplot(sent_pres) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment)) +
ylab("")  #no es muy legible
polarity(data_dictionary_NRC)
library
library
library(quanteda)
library(syuzhet)
library("quanteda.sentiment")
data("data_dictionary_NRC",package = "quanteda.sentiment")
polarity(data_dictionary_NRC)
polarity(data_dictionary_NRC) <- list(pos = "positive", neg = "negative")
polarity(data_dictionary_NRC)
tokens_lookup(toks, data_dictionary_NRC, nested_scope = "dictionary",
exclusive = FALSE)
textstat_polarity(toks, data_dictionary_NRC)
plot(textstat_polarity(toks, data_dictionary_NRC))
plot(textstat_polarity(toks, data_dictionary_NRC))
polarity_q <-textstat_polarity(toks, data_dictionary_NRC)
plot(polarity_q$sentiment)
library("ggplot2")
ggplot(polarity_q) +
geom_point(aes(x = sentiment, y = reorder(doc_id, sentiment))) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment )) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = doc_id), y = sentiment )) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = doc_id), y = sentiment )) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = doc_id, y = sentiment )) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment )) +
ylab("")
library(quanteda)
library(syuzhet)
library("quanteda.sentiment")
library("ggplot2")
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment )) +
ylab("")
ggplot(polarity_q[1:20]) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment )) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id[1:10], sentiment[1:10]), y = sentiment[1:10])) +
ylab("")
plot(polarity_q$doc_id,polarity_q$sentiment)
plot(polarity_q$doc_id,polarity_q$sentiment)
plot(polarity_q$sentiment)
ggplot(polarity_q, aes(x = sentiment)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(polarity_q, aes(x = sentiment, y = doc_id)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(polarity_q, aes(x = doc_id,y = sentiment) +
ggplot(polarity_q, aes(x = doc_id,y = sentiment)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(polarity_q, aes(x = doc_id,y = sentiment)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplotRegression(lm(sentiment ~ doc_id, data = polarity_q))
library("ggplot2")
lm1 <-lm(sentiment ~ doc_id, data = polarity_q)
plot(lm1)
rm(lm1)
plot(sentiment ~ doc_id, data = polarity_q)
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment)) +
ylab("")
plot(polarity_q$sentiment)
plot(polarity_q$sentiment)
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, -sentiment), y = sentiment)) +
ylab("")
ggplot(polarity_q) +
geom_point(aes(x = reorder(doc_id, sentiment), y = sentiment)) +
ylab("")
trust_items <- which(nrc_data$anger > 0)
trust_items
s_v[trust_items]
syuzhet_vector
sum(syuzhet_vector)
rowsum(syuzhet_vector)
sum(syuzhet_vector[,1:15])
sum(syuzhet_vector[,1:15])
head.matrix(syuzhet_vector)
